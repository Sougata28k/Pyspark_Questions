{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most profitable company from the financial sector. Output the result along with the continent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assets:\n",
    "double precision\n",
    "company:\n",
    "text\n",
    "continent:\n",
    "text\n",
    "country:\n",
    "text\n",
    "industry:\n",
    "text\n",
    "marketvalue:\n",
    "double precision\n",
    "profits:\n",
    "double precision\n",
    "rank:\n",
    "bigint\n",
    "sales:\n",
    "double precision\n",
    "sector:\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "company\tsector\tindustry\tcontinent\tcountry\tmarketvalue\tsales\tprofits\tassets\trank\n",
    "ICBC\tFinancials\tMajor Banks\tAsia\tChina\t215.6\t148.7\t42.7\t3124.9\t1\n",
    "Bank of China\tFinancials\tMajor Banks\tAsia\tChina\t124.2\t105.1\t25.5\t2291.8\t9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Start writing code\n",
    "df = forbes_global_2010_2014.filter(col(\"sector\")== 'Financials')\\\n",
    ".orderBy('profits', ascending= False)\\\n",
    ".limit(1)\\\n",
    ".select(\"company\", \"continent\")\n",
    "\n",
    "\n",
    "# To validate your solution, convert your final pySpark df to a pandas df\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question 2 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of employees working in the Admin department that joined in April or later.\n",
    "\n",
    "department:\n",
    "text\n",
    "first_name:\n",
    "text\n",
    "joining_date:\n",
    "date\n",
    "last_name:\n",
    "text\n",
    "salary:\n",
    "bigint\n",
    "worker_id:\n",
    "bigint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worker_id\tfirst_name\tlast_name\tsalary\tjoining_date\tdepartment\n",
    "1\tMonika\tArora\t100000\t2014-02-20\tHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Start writing code\n",
    "df = worker.filter( (month(col(\"joining_date\")) >=4) & (col(\"department\")=='Admin'))\\\n",
    "    .agg(count('*'))\n",
    "\n",
    "# To validate your solution, convert your final pySpark df to a pandas df\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
